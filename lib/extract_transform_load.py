import requests
import pandas as pd
from data.db_connection import DBConnection

class ETL:
    """Extracts data from an API, transforms it, and loads it into a pandas DataFrame."""

    def __init__(self, db_connection):
        """Initializes ETL with a database connection."""
        self.db_connection = db_connection
        self.cursor = self.db_connection.cursor

    def extract(self, url):
        """Fetches and normalizes JSON data from the API."""
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            results = data.get('results', [])
            df = pd.json_normalize(results)
            #print(df.head())
            print("Data extracted successfully.")
            return df
        else:
            print(f"Failed to fetch data. Status code: {response.status_code}")
        
    def transform(self,df,features, extract_feature_idx):
        """Transforms the data by flattening and cleaning it."""
        def get_id_from_url(url):
            return int(url.split('/')[-2]) if url else None

        # Apply the transformation only to specified features
        for feature in features:
            if feature in extract_feature_idx:
                df[feature] = df[feature].apply(get_id_from_url)

        # Automatically convert numeric columns from string to appropriate types
        for column in df.columns:
            if df[column].apply(lambda x: x.isnumeric() if isinstance(x, str) else False).all():
                df[column] = pd.to_numeric(df[column], errors='coerce')

        print("Data transformed successfully.")
        print(df[features].head(100))
        print(df.dtypes)
        return df[features].head(100)

    def load(self, df, table_name):
        """Loads the transformed data into Databricks SQL."""
        columns = [
            f"{col} {'BIGINT' if pd.api.types.is_integer_dtype(df[col]) else 'STRING'}"
            for col in df.columns
        ]
        columns_sql = ", ".join(columns)
        #id BIGINT GENERATED BY DEFAULT AS IDENTITY,
        create_table_query = f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                {columns_sql}
            )
        """
        self.cursor.execute(create_table_query)

        insert_query = f"""
            INSERT INTO {table_name} ({', '.join(df.columns)})
            VALUES ({', '.join(['?'] * len(df.columns))})
        """
        for _, row in df.iterrows():
            self.cursor.execute(insert_query, tuple(row))

        self.db_connection.connection.commit()
        print(f"Data loaded into {table_name}.")


if __name__ == "__main__":
    db_conn = DBConnection()
    db_conn.connect()

    etl = ETL(db_conn)
    df = etl.extract("https://swapi.dev/api/people/")
    features = ['url', "name", "height", "mass", "hair_color", "skin_color", "eye_color", "gender", "homeworld"]
    extract_feature_idx = ['homeworld', 'url']
    df = etl.transform(df, features, extract_feature_idx)
    etl.load(df, "aplt_starwars_people")


    df = etl.extract("https://swapi.dev/api/planets/")
    features = ['url', "name", "rotation_period", "orbital_period", "diameter", "climate", "gravity", "terrain", "surface_water", "population"]
    extract_feature_idx = ['url']
    df = etl.transform(df, features, extract_feature_idx)
    etl.load(df, "aplt_starwars_planets")

    db_conn.close()